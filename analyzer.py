# -*- coding: utf-8 -*-
import os
import re
import random
import string
import math
import jieba
from collections import Counter, defaultdict
import config as cfg
from utils import (
    parse_timestamp,
    parse_datetime,
    clean_text,
    calculate_entropy,
    analyze_single_chars,
)
from logger import get_logger, init_logging

init_logging()

jieba.setLogLevel(jieba.logging.INFO)

logger = get_logger('analyzer')

# å…¨å±€ç¼“å­˜åœç”¨è¯ï¼Œé¿å…é‡å¤è¯»å–
_STOPWORDS_CACHE = None


def load_stopwords():
    """åŠ è½½ç™¾åº¦åœç”¨è¯åº“ï¼Œæ–‡ä»¶ç¼ºå¤±æ—¶è¿”å›ç©ºé›†åˆ"""
    global _STOPWORDS_CACHE
    if _STOPWORDS_CACHE is not None:
        return _STOPWORDS_CACHE
    
    base_dir = os.path.dirname(__file__)
    # å…¼å®¹ä¸¤ç§æ”¾ç½®æ–¹å¼ï¼šé¡¹ç›®æ ¹ç›®å½•çš„ resources/ å’Œ backend/resources/
    candidate_paths = [
        os.path.join(base_dir, 'resources', 'baidu_stopwords.txt'),
        os.path.join(base_dir, 'backend', 'resources', 'baidu_stopwords.txt'),
    ]

    stopwords_path = None
    for p in candidate_paths:
        if os.path.exists(p):
            stopwords_path = p
            break

    if not stopwords_path:
        logger.warning(f"åœç”¨è¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è·¯å¾„: {candidate_paths}")
        _STOPWORDS_CACHE = set()
        return _STOPWORDS_CACHE

    with open(stopwords_path, 'r', encoding='utf-8') as f:
        words = {line.strip() for line in f if line.strip() and not line.startswith('#')}

    _STOPWORDS_CACHE = words
    logger.info(f"ğŸ“š å·²åŠ è½½åœç”¨è¯ {len(words)} ä¸ª")
    return _STOPWORDS_CACHE


class ChatAnalyzer:
    def __init__(self, data, use_stopwords=False, stopwords=None):
        self.data = data
        self.messages = data.get('messages', [])
        self.chat_name = data.get('chatName', data.get('chatInfo', {}).get('name', 'æœªçŸ¥ç¾¤èŠ'))
        self.use_stopwords = use_stopwords
        self.stopwords = stopwords if stopwords is not None else (load_stopwords() if use_stopwords else set())
        
        # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
        self._filter_messages_by_time()
        self.uin_to_name = {}
        self.msgid_to_sender = {}
        self.word_freq = Counter()
        self.word_samples = defaultdict(list)
        self.word_contributors = defaultdict(Counter)
        self.user_msg_count = Counter()
        self.user_char_count = Counter()
        self.user_char_per_msg = {}
        self.user_image_count = Counter()
        self.user_forward_count = Counter()
        self.user_reply_count = Counter()
        self.user_replied_count = Counter()
        self.user_at_count = Counter()
        self.user_ated_count = Counter()
        self.user_emoji_count = Counter()
        self.user_link_count = Counter()
        self.user_night_count = Counter()
        self.user_morning_count = Counter()
        self.user_repeat_count = Counter()
        self.hour_distribution = Counter()
        self.discovered_words = set()
        self.merged_words = {}
        self.single_char_stats = {}  # å•å­—ç»Ÿè®¡
        self.cleaned_texts = []  # ç¼“å­˜æ¸…æ´—åçš„æ–‡æœ¬
        self._build_mappings()
    
    def _filter_messages_by_time(self):
        """æ ¹æ®é…ç½®çš„æ—¶é—´èŒƒå›´è¿‡æ»¤æ¶ˆæ¯"""
        if cfg.MESSAGE_START_DATE is None and cfg.MESSAGE_END_DATE is None:
            return
        
        from datetime import datetime
        
        # è§£æé…ç½®çš„æ—¥æœŸ
        start_dt = None
        end_dt = None
        
        if cfg.MESSAGE_START_DATE:
            try:
                start_dt = datetime.strptime(cfg.MESSAGE_START_DATE, '%Y-%m-%d')
                start_dt = start_dt.replace(hour=0, minute=0, second=0, microsecond=0)
                # è½¬æ¢ä¸ºä¸œå…«åŒº
                from datetime import timezone, timedelta
                start_dt = start_dt.replace(tzinfo=timezone(timedelta(hours=8)))
            except Exception as e:
                logger.warning(f"èµ·å§‹æ—¥æœŸæ ¼å¼é”™è¯¯: {cfg.MESSAGE_START_DATE}, é”™è¯¯: {e}")
        
        if cfg.MESSAGE_END_DATE:
            try:
                end_dt = datetime.strptime(cfg.MESSAGE_END_DATE, '%Y-%m-%d')
                end_dt = end_dt.replace(hour=23, minute=59, second=59, microsecond=999999)
                # è½¬æ¢ä¸ºä¸œå…«åŒº
                from datetime import timezone, timedelta
                end_dt = end_dt.replace(tzinfo=timezone(timedelta(hours=8)))
            except Exception as e:
                logger.warning(f"ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯: {cfg.MESSAGE_END_DATE}, é”™è¯¯: {e}")
        
        if start_dt is None and end_dt is None:
            return  # æ—¥æœŸè§£æå¤±è´¥ï¼Œä¸è¿‡æ»¤
        
        # è¿‡æ»¤æ¶ˆæ¯
        original_count = len(self.messages)
        filtered_messages = []
        
        for msg in self.messages:
            timestamp = msg.get('timestamp', '')
            msg_dt = parse_datetime(timestamp)
            
            if msg_dt is None:
                continue 
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
            if start_dt and msg_dt < start_dt:
                continue
            if end_dt and msg_dt > end_dt:
                continue
            
            filtered_messages.append(msg)
        
        self.messages = filtered_messages
        filtered_count = len(self.messages)
        
        if start_dt or end_dt:
            time_range = []
            if start_dt:
                time_range.append(f"ä» {cfg.MESSAGE_START_DATE}")
            if end_dt:
                time_range.append(f"åˆ° {cfg.MESSAGE_END_DATE}")
            logger.info(f"â° æ—¶é—´èŒƒå›´è¿‡æ»¤: {' '.join(time_range)}")
            logger.info(f"   åŸå§‹æ¶ˆæ¯: {original_count} æ¡, è¿‡æ»¤å: {filtered_count} æ¡")

    def _is_bot_message(self, msg):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœºå™¨äººæ¶ˆæ¯ï¼ˆåŸºäº subMsgTypeï¼‰"""
        if not cfg.FILTER_BOT_MESSAGES:
            return False
        
        raw_msg = msg.get('rawMessage', {})
        sub_msg_type = raw_msg.get('subMsgType', 0)
        return sub_msg_type in [577, 65]

    def _build_mappings(self):
        # æ„å»º uin åˆ° name çš„æ˜ å°„ï¼Œä¼˜å…ˆä¿ç•™æœ‰æ•ˆçš„ name
        # å…ˆæ”¶é›†æ¯ä¸ª uin çš„æ‰€æœ‰ nameï¼ˆæŒ‰é¡ºåºï¼‰å’Œ sendMemberName
        uin_names = defaultdict(list)
        uin_member_names = {}  # å­˜å‚¨æœ€åçš„ sendMemberName
        
        for msg in self.messages:
            if self._is_bot_message(msg):
                continue
            
            sender = msg.get('sender', {})
            uin = sender.get('uin')
            name = sender.get('name', '').strip()
            msg_id = msg.get('messageId')
            
            if uin and name:
                # åªåœ¨ name ä¸ä¸Šä¸€ä¸ªä¸åŒæ—¶æ·»åŠ 
                if not uin_names[uin] or uin_names[uin][-1] != name:
                    uin_names[uin].append(name)
            
            # æ”¶é›† sendMemberNameï¼ˆä¿ç•™æœ€åä¸€ä¸ªï¼‰
            if uin:
                raw_msg = msg.get('rawMessage', {})
                send_member_name = raw_msg.get('sendMemberName', '').strip()
                if send_member_name:
                    uin_member_names[uin] = send_member_name
            
            if msg_id and uin:
                self.msgid_to_sender[msg_id] = uin
        
        # ä¸ºæ¯ä¸ª uin é€‰æ‹©æœ€åˆé€‚çš„ name
        for uin, names in uin_names.items():
            # ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ªä¸ç­‰äºuinçš„ name
            chosen_name = None
            for name in reversed(names):
                if name != str(uin):
                    chosen_name = name
                    break
            
            # å¦‚æœæ‰€æœ‰ name éƒ½ç­‰äº uinï¼Œä½¿ç”¨ sendMemberName
            if chosen_name is None:
                if uin in uin_member_names:
                    chosen_name = uin_member_names[uin]
                elif names:
                    chosen_name = names[-1]  # å…œåº•ï¼šä½¿ç”¨æœ€åä¸€ä¸ª
            
            if chosen_name:
                self.uin_to_name[uin] = chosen_name

    def get_name(self, uin):
        return self.uin_to_name.get(uin, f"æœªçŸ¥ç”¨æˆ·({uin})")

    def analyze(self):
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ: {self.chat_name}")
        logger.info(f"ğŸ“ æ¶ˆæ¯æ€»æ•°: {len(self.messages)}")
        
        logger.info("ğŸ§¹ é¢„å¤„ç†æ–‡æœ¬...")
        self._preprocess_texts()
        
        logger.info("ğŸ”¤ åˆ†æå•å­—ç‹¬ç«‹æ€§...")
        self.single_char_stats = analyze_single_chars(self.cleaned_texts)
        
        logger.info("ğŸ” æ–°è¯å‘ç°...")
        self._discover_new_words()
        
        logger.info("ğŸ”— è¯ç»„åˆå¹¶...")
        self._merge_word_pairs()
        
        logger.info("ğŸ“ˆ åˆ†è¯ç»Ÿè®¡...")
        self._tokenize_and_count()
        
        logger.info("ğŸ® è¶£å‘³ç»Ÿè®¡...")
        self._fun_statistics()
        
        logger.info("ğŸ§¹ è¿‡æ»¤æ•´ç†...")
        self._filter_results()
        
        logger.info("âœ… åˆ†æå®Œæˆ!")

    def _preprocess_texts(self):
        """é¢„å¤„ç†æ‰€æœ‰æ–‡æœ¬"""
        skipped = 0
        bot_filtered = 0
        for msg in self.messages:
            # è·³è¿‡æœºå™¨äººæ¶ˆæ¯
            if self._is_bot_message(msg):
                bot_filtered += 1
                continue
            
            content = msg.get('content', {})
            text = content.get('text', '') if isinstance(content, dict) else ''
            cleaned = clean_text(text)
            if cleaned and len(cleaned) >= 1:
                self.cleaned_texts.append(cleaned)
            elif text:
                skipped += 1
        
        if cfg.FILTER_BOT_MESSAGES and bot_filtered > 0:
            logger.debug(f"æœ‰æ•ˆæ–‡æœ¬: {len(self.cleaned_texts)} æ¡, è·³è¿‡: {skipped} æ¡, è¿‡æ»¤æœºå™¨äºº: {bot_filtered} æ¡")
        else:
            logger.debug(f"æœ‰æ•ˆæ–‡æœ¬: {len(self.cleaned_texts)} æ¡, è·³è¿‡: {skipped} æ¡")

    def _discover_new_words(self):
        """æ–°è¯å‘ç°"""
        ngram_freq = Counter()
        left_neighbors = defaultdict(Counter)
        right_neighbors = defaultdict(Counter)
        total_chars = 0
        
        for text in self.cleaned_texts:
            sentences = re.split(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰\s\n\r,\.!?\(\)]', text)
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 2:
                    continue
                total_chars += len(sentence)
                
                for n in range(2, min(6, len(sentence) + 1)):
                    for i in range(len(sentence) - n + 1):
                        ngram = sentence[i:i+n]
                        # åªè·³è¿‡çº¯ç©ºæ ¼
                        if not ngram.strip():
                            continue
                        ngram_freq[ngram] += 1
                        if i > 0:
                            left_neighbors[ngram][sentence[i-1]] += 1
                        else:
                            left_neighbors[ngram]['<BOS>'] += 1
                        if i + n < len(sentence):
                            right_neighbors[ngram][sentence[i+n]] += 1
                        else:
                            right_neighbors[ngram]['<EOS>'] += 1
        
        for word, freq in ngram_freq.items():
            if freq < cfg.NEW_WORD_MIN_FREQ:
                continue
            
            # é‚»æ¥ç†µ
            left_ent = calculate_entropy(left_neighbors[word])
            right_ent = calculate_entropy(right_neighbors[word])
            min_ent = min(left_ent, right_ent)
            if min_ent < cfg.ENTROPY_THRESHOLD:
                continue
            
            # PMI
            min_pmi = float('inf')
            for i in range(1, len(word)):
                left_freq = ngram_freq.get(word[:i], 0)
                right_freq = ngram_freq.get(word[i:], 0)
                if left_freq > 0 and right_freq > 0:
                    pmi = math.log2((freq * total_chars) / (left_freq * right_freq + 1e-10))
                    min_pmi = min(min_pmi, pmi)
            
            if min_pmi == float('inf'):
                min_pmi = 0
            
            if min_pmi < cfg.PMI_THRESHOLD:
                continue
            
            self.discovered_words.add(word)
        
        for word in self.discovered_words:
            jieba.add_word(word, freq=1000)
        
        logger.debug(f"å‘ç° {len(self.discovered_words)} ä¸ªæ–°è¯")

    def _merge_word_pairs(self):
        bigram_counter = Counter()
        word_right_counter = Counter()
        
        for text in self.cleaned_texts:
            words = [w for w in jieba.cut(text) if w.strip()]
            for i in range(len(words) - 1):
                w1, w2 = words[i].strip(), words[i+1].strip()
                if not w1 or not w2:
                    continue
                if re.match(r'^[\d\W]+$', w1) or re.match(r'^[\d\W]+$', w2):
                    continue
                bigram_counter[(w1, w2)] += 1
                word_right_counter[w1] += 1
        
        for (w1, w2), count in bigram_counter.items():
            merged = w1 + w2
            if len(merged) > cfg.MERGE_MAX_LEN:
                continue
            if count < cfg.MERGE_MIN_FREQ:
                continue
            
            # æ¡ä»¶æ¦‚ç‡ P(w2|w1)
            if word_right_counter[w1] > 0:
                prob = count / word_right_counter[w1]
                if prob >= cfg.MERGE_MIN_PROB:
                    self.merged_words[merged] = (w1, w2, count, prob)
                    jieba.add_word(merged, freq=count * 1000)
        
        logger.debug(f"åˆå¹¶ {len(self.merged_words)} ä¸ªè¯ç»„")
        
        if self.merged_words:
            sorted_merges = sorted(self.merged_words.items(), key=lambda x: -x[1][2])[:10]
            for merged, (w1, w2, cnt, prob) in sorted_merges:
                logger.debug(f"  {merged}: {w1}+{w2} ({cnt}æ¬¡, {prob:.0%})")

    def _tokenize_and_count(self):
        for idx, msg in enumerate(self.messages):
            if self._is_bot_message(msg):
                continue
            
            sender_uin = msg.get('sender', {}).get('uin')
            content = msg.get('content', {})
            text = content.get('text', '') if isinstance(content, dict) else ''
            original_text = text
            cleaned = clean_text(text)
            
            if not cleaned:
                continue
            
            words = list(jieba.cut(cleaned))
            
            for word in words:
                word = word.strip()
                if not word:
                    continue
                
                if self.use_stopwords and word in self.stopwords:
                    continue

                # æå‰è¿‡æ»¤é»‘åå•ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šé¿å…ç»Ÿè®¡åå†è¿‡æ»¤ï¼‰
                if word in cfg.BLACKLIST:
                    continue
                
                self.word_freq[word] += 1
                if sender_uin:
                    self.word_contributors[word][sender_uin] += 1
                if len(self.word_samples[word]) < cfg.SAMPLE_COUNT * 3:
                    self.word_samples[word].append(cleaned)

    def _fun_statistics(self):
        """è¶£å‘³ç»Ÿè®¡"""
        prev_clean = None  
        prev_sender = None
        
        for msg in self.messages:
            if self._is_bot_message(msg):
                continue
            
            sender_uin = msg.get('sender', {}).get('uin')
            if not sender_uin:
                continue
            
            content = msg.get('content', {})
            text = content.get('text', '') if isinstance(content, dict) else ''
            timestamp = msg.get('timestamp', '')
            raw = msg.get('rawMessage', {})
            elements = raw.get('elements', [])
            
            self.user_msg_count[sender_uin] += 1
            clean = clean_text(text)
            self.user_char_count[sender_uin] += len(clean)
            
            has_image = False
            is_emoji_image = False
            has_forward = False
            has_link = False
            emoji_count_from_elements = 0
            
            for elem in elements:
                elem_type = elem.get('elementType')
                
                # è·³è¿‡å›å¤å…ƒç´ 
                if elem_type == 7:
                    continue
                
                # å›¾ç‰‡å…ƒç´  
                if elem_type == 2:
                    has_image = True
                    pic_elem = elem.get('picElement', {})
                    summary = pic_elem.get('summary', '')
                    # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨æƒ…å›¾ç‰‡
                    if summary and summary.startswith('[') and summary.endswith(']'):
                        is_emoji_image = True
                        emoji_count_from_elements += 1
                
                # æ–‡æœ¬å…ƒç´ 
                elif elem_type == 1:
                    text_elem = elem.get('textElement', {})
                    
                    # @ç»Ÿè®¡
                    at_type = text_elem.get('atType', 0)
                    at_uid = text_elem.get('atUid', '')
                    if at_type > 0 and at_uid and at_uid != '0':
                        self.user_at_count[sender_uin] += 1
                        self.user_ated_count[at_uid] += 1
                    
                    # é“¾æ¥ç»Ÿè®¡ï¼ˆæ–‡æœ¬ä¸­çš„é“¾æ¥ï¼‰
                    if not has_link:
                        text_content = text_elem.get('content', '')
                        if re.search(r'https?://', text_content):
                            has_link = True
                
                # é“¾æ¥å…ƒç´ 
                elif elem_type == 10:
                    has_link = True
                
                # è½¬å‘å…ƒç´ 
                elif elem_type == 16 and 'multiForwardMsgElement' in elem:
                    has_forward = True
            
            # ========== å›¾ç‰‡ç»Ÿè®¡ï¼ˆcontent.resources ä¸­æœ‰å›¾ç‰‡ ä¸” éè¡¨æƒ…ï¼‰ ==========
            resources = content.get('resources', []) if isinstance(content, dict) else []
            has_image_resource = any(res.get('type') == 'image' for res in resources)
            if has_image_resource and not is_emoji_image:
                self.user_image_count[sender_uin] += 1
            
            # ========== è½¬å‘ç»Ÿè®¡ ==========
            if has_forward:
                self.user_forward_count[sender_uin] += 1
            
            # ========== å›å¤ç»Ÿè®¡ ==========
            reply_info = content.get('reply') if isinstance(content, dict) else None
            if reply_info:
                self.user_reply_count[sender_uin] += 1
                ref_msg_id = reply_info.get('referencedMessageId')
                if ref_msg_id and ref_msg_id in self.msgid_to_sender:
                    target_uin = self.msgid_to_sender[ref_msg_id]
                    self.user_replied_count[target_uin] += 1
            
            # ========== è¡¨æƒ…ç»Ÿè®¡ ==========
            # content.emojis ä¸­çš„QQè¡¨æƒ…
            emojis = content.get('emojis', []) if isinstance(content, dict) else []
            emoji_count = len(emojis) + emoji_count_from_elements
            if emoji_count > 0:
                self.user_emoji_count[sender_uin] += emoji_count
            
            # ========== é“¾æ¥ç»Ÿè®¡ ==========
            if has_link:
                self.user_link_count[sender_uin] += 1
            
            # ========== æ—¶æ®µç»Ÿè®¡ ==========
            hour = parse_timestamp(timestamp)
            if hour is not None:
                self.hour_distribution[hour] += 1
                if hour in cfg.NIGHT_OWL_HOURS:
                    self.user_night_count[sender_uin] += 1
                if hour in cfg.EARLY_BIRD_HOURS:
                    self.user_morning_count[sender_uin] += 1
            
            # ========== å¤è¯»ç»Ÿè®¡ ==========
            if clean and len(clean) >= 2:
                if clean == prev_clean and sender_uin != prev_sender:
                    self.user_repeat_count[sender_uin] += 1
            
            prev_clean = clean if clean else prev_clean
            prev_sender = sender_uin
        
        # ========== è®¡ç®—äººå‡å­—æ•°ï¼ˆä¿ç•™1ä½å°æ•°ï¼‰ ==========
        for uin in self.user_msg_count:
            msg_count = self.user_msg_count[uin]
            char_count = self.user_char_count[uin]
            if msg_count >= 10:
                self.user_char_per_msg[uin] = round(char_count / msg_count, 1)


    def _filter_results(self):
        """è¿‡æ»¤ç»“æœ"""
        filtered_freq = Counter()
        
        for word, freq in self.word_freq.items():
            if len(word) < cfg.MIN_WORD_LEN or len(word) > cfg.MAX_WORD_LEN:
                continue
            if freq < cfg.MIN_FREQ:
                continue
            
            if word in cfg.WHITELIST:
                filtered_freq[word] = freq
                continue
            
            if word in cfg.BLACKLIST:
                continue
            
            # å•å­—ç‰¹æ®Šå¤„ç†
            if len(word) == 1:
                # å•ä¸ªç¬¦å·è·³è¿‡ï¼ˆä½†æ•°å­—/å­—æ¯èµ°å•å­—ç»Ÿè®¡ï¼‰
                if word in string.punctuation or word in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€""''ï¼ˆï¼‰ã€ã€‘':
                    continue
                # å…¶ä»–å•å­—ï¼ˆæ•°å­—/å­—æ¯/æ±‰å­—ï¼‰èµ°ç‹¬ç«‹æ€§æ£€æŸ¥
                stats = self.single_char_stats.get(word)
                if stats:
                    total, indep, ratio = stats
                    if ratio < cfg.SINGLE_MIN_SOLO_RATIO or indep < cfg.SINGLE_MIN_SOLO_COUNT:
                        continue
                else:
                    continue
                        
            filtered_freq[word] = freq
        
        self.word_freq = filtered_freq
        
        # é‡‡æ ·
        for word in self.word_samples:
            samples = self.word_samples[word]
            if len(samples) > cfg.SAMPLE_COUNT:
                self.word_samples[word] = random.sample(samples, cfg.SAMPLE_COUNT)
        
        logger.debug(f"è¿‡æ»¤å {len(self.word_freq)} ä¸ªè¯")

    def get_top_words(self, n=None):
        n = n or cfg.TOP_N
        return self.word_freq.most_common(n)

    def get_word_detail(self, word):
        return {
            'word': word,
            'freq': self.word_freq.get(word, 0),
            'samples': self.word_samples.get(word, []),
            'contributors': [(self.get_name(uin), count) 
                           for uin, count in self.word_contributors[word].most_common(cfg.CONTRIBUTOR_TOP_N)]
        }

    def get_fun_rankings(self):
        rankings = {}
        
        def fmt(counter, top_n=cfg.RANK_TOP_N):
            return [(self.get_name(uin), count) for uin, count in counter.most_common(top_n)]
        
        rankings['è¯ç—¨æ¦œ'] = fmt(self.user_msg_count)
        rankings['å­—æ•°æ¦œ'] = fmt(self.user_char_count)
        
        sorted_avg = sorted(self.user_char_per_msg.items(), key=lambda x: x[1], reverse=True)[:cfg.RANK_TOP_N]
        rankings['é•¿æ–‡ç‹'] = [(self.get_name(uin), f"{avg:.1f}å­—/æ¡") for uin, avg in sorted_avg]
        
        rankings['å›¾ç‰‡ç‹‚é­”'] = fmt(self.user_image_count)
        rankings['åˆå¹¶è½¬å‘ç‹'] = fmt(self.user_forward_count)
        rankings['å›å¤ç‹‚'] = fmt(self.user_reply_count)
        rankings['è¢«å›å¤æœ€å¤š'] = fmt(self.user_replied_count)
        rankings['è‰¾ç‰¹ç‹‚'] = fmt(self.user_at_count)
        rankings['è¢«è‰¾ç‰¹æœ€å¤š'] = fmt(self.user_ated_count)
        rankings['è¡¨æƒ…å¸'] = fmt(self.user_emoji_count)
        rankings['é“¾æ¥åˆ†äº«ç‹'] = fmt(self.user_link_count)
        rankings['æ·±å¤œå…š'] = fmt(self.user_night_count)
        rankings['æ—©èµ·é¸Ÿ'] = fmt(self.user_morning_count)
        rankings['å¤è¯»æœº'] = fmt(self.user_repeat_count)
        
        return rankings
    
    def export_json(self):
        """å¯¼å‡ºJSONæ ¼å¼ç»“æœï¼ˆåŒ…å«uinä¿¡æ¯ï¼‰"""
        top_words = []
        for word, freq in self.get_top_words():
            # å†æ¬¡åœ¨å¯¼å‡ºé˜¶æ®µè¿‡æ»¤åœç”¨è¯ï¼Œä¿è¯æŠ¥å‘Šä¸­ä¸åŒ…å«åœç”¨è¯
            if self.use_stopwords and word in self.stopwords:
                continue
            top_words.append({
                'word': word,
                'freq': freq,
                'contributors': [
                    {
                        'name': self.get_name(uin),
                        'uin': uin,
                        'count': count
                    }
                    for uin, count in self.word_contributors[word].most_common(cfg.CONTRIBUTOR_TOP_N)
                ],
                'samples': self.word_samples.get(word, [])[:cfg.SAMPLE_COUNT]
            })

        result = {
            'chatName': self.chat_name,
            'messageCount': len(self.messages),
            'topWords': top_words,
            'rankings': {},
            'hourDistribution': {str(h): self.hour_distribution.get(h, 0) for h in range(24)}
        }
        
        # è¶£å‘³æ¦œå•ï¼ˆåŒ…å«uinï¼‰
        def fmt_with_uin(counter, top_n=cfg.RANK_TOP_N):
            return [
                {'name': self.get_name(uin), 'uin': uin, 'value': count}
                for uin, count in counter.most_common(top_n)
            ]
        
        result['rankings']['è¯ç—¨æ¦œ'] = fmt_with_uin(self.user_msg_count)
        result['rankings']['å­—æ•°æ¦œ'] = fmt_with_uin(self.user_char_count)
        
        # é•¿æ–‡ç‹ç‰¹æ®Šå¤„ç†
        sorted_avg = sorted(self.user_char_per_msg.items(), key=lambda x: x[1], reverse=True)[:cfg.RANK_TOP_N]
        result['rankings']['é•¿æ–‡ç‹'] = [
            {'name': self.get_name(uin), 'uin': uin, 'value': f"{avg:.1f}å­—/æ¡"}
            for uin, avg in sorted_avg
        ]
        
        result['rankings']['å›¾ç‰‡ç‹‚é­”'] = fmt_with_uin(self.user_image_count)
        result['rankings']['åˆå¹¶è½¬å‘ç‹'] = fmt_with_uin(self.user_forward_count)
        result['rankings']['å›å¤ç‹‚'] = fmt_with_uin(self.user_reply_count)
        result['rankings']['è¢«å›å¤æœ€å¤š'] = fmt_with_uin(self.user_replied_count)
        result['rankings']['è‰¾ç‰¹ç‹‚'] = fmt_with_uin(self.user_at_count)
        result['rankings']['è¢«è‰¾ç‰¹æœ€å¤š'] = fmt_with_uin(self.user_ated_count)
        result['rankings']['è¡¨æƒ…å¸'] = fmt_with_uin(self.user_emoji_count)
        result['rankings']['é“¾æ¥åˆ†äº«ç‹'] = fmt_with_uin(self.user_link_count)
        result['rankings']['æ·±å¤œå…š'] = fmt_with_uin(self.user_night_count)
        result['rankings']['æ—©èµ·é¸Ÿ'] = fmt_with_uin(self.user_morning_count)
        result['rankings']['å¤è¯»æœº'] = fmt_with_uin(self.user_repeat_count)
        
        return result
